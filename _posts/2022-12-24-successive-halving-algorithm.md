---
title: Successive Halving Algorithm
tags: [hpo, sha, multi-fidelity]
category: ML
aside:
  toc: true
show_category: true
---

π“„ Jamieson, Kevin, and Ameet Talwalkar. "Non-stochastic best arm identification and hyperparameter optimization." *Artificial intelligence and statistics*. PMLR, 2016.

<!--more-->

## Non-stochastic Best Arm Identification

Successive Halving Algorithmμ€ Bandit κΈ°λ°μ ν•μ΄νΌνλΌλ―Έν„° μµμ ν™” κΈ°λ²•μ…λ‹λ‹¤. Banditμ΄λΌλ” λ‹¨μ–΄λ¥Ό λ“¤μΌλ©΄ κ°€μ¥ λ¨Όμ € λ– μ¤λ¥΄λ” κ²ƒμ΄ A/B ν…μ¤νΈμ— λ§μ΄ μ‚¬μ©λλ” Multi-armed Banditμ…λ‹λ‹¤. μ—¬λ¬ κ°μ μ¬λ΅―λ¨Έμ‹ μ΄ μκ³ , κ·Έ μ¬λ΅―λ¨Έμ‹ μ ν” (arm)μ„ λ‹Ήκ²¨μ„ λ³΄μƒ (reward)μ„ μ–»κ² λ©λ‹λ‹¤. μ΄ λ³΄μƒμ€ μ–΄λ–¤ ν™•λ¥  λ¶„ν¬λ΅ λ‚νƒ€λ‚λ”λ°, μ–΄λ–¤ μ „λµμΌλ΅ μ¬λ΅―λ¨Έμ‹ μ„ κ³¨λΌμ•Ό μµλ€μ λ³΄μƒμ„ μ–»λ”μ§€μ— κ΄€ν• λ‚΄μ©μ΄ λ°”λ΅ MABμ…λ‹λ‹¤. MAB λ¬Έμ λ¥Ό ν‘Έλ” λ°©λ²•μ€ ν¬κ² λ‘ κ°λ΅ λ‚λ μ μλ”λ°μ”. ν•λ‚λ” κ°€μ¥ ν° λ³΄μƒμ„ μ£Όλ” μµμ„ μ μ¬λ΅―λ¨Έμ‹ μ ν”μ„ μ°Ύλ” κ²ƒμ΄κ³ , ν•λ‚λ” μΌλ°μ μΌλ΅ λ§μ΄ λ‹¤λ£¨λ” Exploration-Exploitation Trade-offλ¥Ό ν•΄κ²°ν•λ” κ²ƒμ…λ‹λ‹¤. λ³Έ κΈ€μ—μ„ λ‹¤λ£¨λ” Successive Halving Algorithmμ€ μ²« λ²μ§Έ λ°©λ²•μΈ **Best Arm Identification**μ„ κΈ°λ°μ— λ‘κ³  μμµλ‹λ‹¤.

### Stochastic vs Non-stochastic

Best Arm Identification λ°©λ²•λ„ ν¬κ² Stochasticν• ν™κ²½κ³Ό Non-stochasticν• ν™κ²½μΌλ΅ λ‚λ‰©λ‹λ‹¤. λ…Όλ¬Έμ—μ„λ” μ΄λ ‡κ² ν‘ν„ν•κ³  μμµλ‹λ‹¤.

>π° **Stochastic**
>
>λ¨λ“  $i \in [n], k \geq 1$μ— λ€ν•΄μ„ $\mathbb{E}[\ell_{i, k}] = \mu_i$λ¥Ό λ§μ΅±ν•λ” $\ell_{i,k}$λ¥Ό $[0, 1]$ κµ¬κ°„ λ‚΄μ **ν™•λ¥  λ¶„ν¬μ—μ„ λ½‘μ€ i.i.d μƒν”**λ΅ λ‘μ.
>μ΄λ• $\sum^n_{i=1} T_i$λ¥Ό μµμ†ν™”ν•λ” λ™μ• $\arg\min_i \mu_i$λ¥Ό μ°Ύλ” κ²ƒμ΄ λ©μ μ΄λ‹¤.
>
>π― **Non-stochastic**
>
>λ¨λ“  $i \in [n], k\geq 1$μ— λ€ν•΄μ„ **μ•κ³ λ¦¬μ¦μ ν–‰λ™μ— λ…λ¦½μ μΈ Loss sequence $\ell_{i, k} \in \mathbb{R}$μ„ μƒμ„±**ν•λ‹¤κ³  ν•μ. λ” λ‚μ•„κ°€ $\nu_i = \lim_{\tau \to \infty} \ell_{i, \tau}$κ°€ μ΅΄μ¬ν•λ‹¤κ³  κ°€μ •ν•μ.
>μ΄λ• $\sum^n_{i=1} T_i$λ¥Ό μµμ†ν™”ν•λ” λ™μ• $\arg\min_{i} \nu_i$λ¥Ό μ°Ύλ” κ²ƒμ΄ λ©μ μ΄λ‹¤.

ν‘ν„μ΄ μ–΄λ µμ§€λ§ κ° ν™κ²½μ—μ„ μ¤‘μ”ν• λ¶€λ¶„μ€ **$\ell_{i, k}$λ¥Ό μ–΄λ–»κ² μ •μν•λλƒ**μ…λ‹λ‹¤. Stochasticν• λ°©λ²•μ€ $\ell_{i, k}$λ¥Ό ν™•λ¥  λ¶„ν¬μ—μ„ λ½‘μ€ i.i.d μƒν”μ„, Non-stochasticν• λ°©λ²•μ—μ„λ” μ•κ³ λ¦¬μ¦μ— λ…λ¦½μ μΈ μ–΄λ–¤ μμ—΄μ„ μƒμ„±ν•©λ‹λ‹¤.

ν•μ΄νΌνλΌλ―Έν„° μµμ ν™”λ” Non-stochastic ν™κ²½μ—μ„μ Bandit λ¬Έμ λ΅ λ³Ό μ μμµλ‹λ‹¤. μ¬λ΅―λ¨Έμ‹ μ ν”μ€ ν•λ‚μ ν•μ΄νΌνλΌλ―Έν„° μ„¤μ •μΌλ΅, $\ell_{i, k}$λ” ν•™μµν•λ” λ¨λΈμ μ†μ‹¤ ν•¨μ κ°’μΌλ΅ λ³Ό μ μμµλ‹λ‹¤. μ΄λ• non-stochasticν•κ³  obliviousν• κ²°κ³Όλ¥Ό μ–»κ² λλ”λ°μ”. μ†μ‹¤ ν•¨μμ κ°’μ€ **ν™•λ¥ μ μ΄ μ•„λ‹ κ²°μ •λ΅ μ (deterministic)μΌλ΅** λ‚μ¤κ³ , κ°κ°μ ν•μ΄νΌνλΌλ―Έν„° μ„¤μ •κ³Ό μ†μ‹¤ ν•¨μμ κ°’μ— λ€ν• **μ •λ³΄λ¥Ό κ³µμ ν•μ§€ μ•κΈ° λ•λ¬Έ**μ…λ‹λ‹¤. μ΄λ° κ΄€μ μ—μ„ λ³Έ λ…Όλ¬Έμ—μ„λ„ Non-stochasticν• Best Arm IdentificationμΌλ΅ ν”„λ μ΄λ°ν•μ—¬ λ°©λ²•λ΅ μ„ μ μ•ν•κ³  μμµλ‹λ‹¤.

### Non-stochasticμ΄ μ‰½μ§€ μ•μ€ μ΄μ 

Stochasticν• ν™κ²½μ€ λ‡ κ°€μ§€ μ„¤μ •μ„ ν†µν•΄ Non-stochasticν• ν™κ²½μΌλ΅ λ°”λ€” μ μμµλ‹λ‹¤. Stochasticν• ν™κ²½μ—μ„μ Loss κ°’μΈ $\ell^\prime\_{i, T_i}$ λ¥Ό μ΄μ©ν•΄ $\ell\_{i, T_i} = \frac{1}{T_i} \sum^{T_i}_{k=1} \ell^\prime\_{i, T_i}$ λ΅ μ„¤μ •ν•λ©΄ λ©λ‹λ‹¤. μ΄ λ• ν° μμ λ²•μΉ™μ— μν•΄ λ‹¤μμ΄ μ„±λ¦½ν•©λ‹λ‹¤.

$$
\lim_{\tau \to \infty} \ell_{i, \tau} = \mathbb{E}[\ell^\prime_{i, 1}].
$$

κ·Έλ¦¬κ³  $\ell\_{i, T_i} = \min \left\\{ \ell^\prime\_{i, 1}, \cdots, \ell^\prime\_{i, T_i} \right \\}$ λ΅ λ‘”λ‹¤λ©΄ $\ell\_{i, t}$ λ” bounded, monotonically decreasing sequenceκ°€ λ©λ‹λ‹¤. λ”°λΌμ„ $\ell\_{i, t}$ λ” [Monotone Convergence Theorem](https://en.wikipedia.org/wiki/Monotone_convergence_theorem)μ— μν•΄ λ°λ“μ‹ κ·Ήν•κ°’μ„ κ°–κ² λ©λ‹λ‹¤.

Stochasticν• ν™κ²½κ³Ό Non-stochasticν• ν™κ²½μ μ°¨μ΄λ” κ·Ήν•κ°’μΌλ΅ μλ ΄ν•λ” μ†λ„μ—μ„ λ‚νƒ€λ‚©λ‹λ‹¤. Stochasticν• ν™κ²½μ€ μλ ΄ν•λ” μ†λ„λ¥Ό μ• μ μμ§€λ§ Non-stochastic ν™κ²½μ€ μ• μ μ—†μµλ‹λ‹¤. Stochasticν• μ„¤μ •μ—μ„ $\hat{\mu}\_{i, T_i} = \frac{1}{T_i} \sum^{T_i}\_{k=1} \ell\_{i, k}$λ΅ λ’€μ„ λ• λ¨λ“  $i \in [n], T_i > 0$ μ— λ€ν•΄ λ‹¤μμ„ λ§μ΅±ν•©λ‹λ‹¤.

$$
\left| \hat{\mu}_{i, T_i} - \mu_i \right| \leq \sqrt{\frac{\log(4nT_i^2)}{2T_i}}.
$$


>π§ **μ΄ μ‹μ΄ μ„±λ¦½ν•λ” μ΄μ λ”?**
>
>*$X_t$κ°€ $[0, 1]$ μ•μ— μκ³ , $n > 1$ μΌ λ• λ‹¤μμ΄ μ„±λ¦½ν•λ‹¤.*
>
>$$ P \left( \bigcup^\infty_{t=1} \left\{ \left| \frac{1}{t} \sum^t_{s=1} X_s - \mathbb{E}[X_s] \right| \geq \sqrt{\frac{\log(4nt^2)}{2t}} \right\} \right) \leq \frac{1}{n}. $$
>
>**μ¦λ….**
>
>[Boole's Inequality](https://en.wikipedia.org/wiki/Boole%27s_inequality)μ— μν•΄μ„ λ‹¤μμ΄ μ„±λ¦½ν•©λ‹λ‹¤.
>
>$$ P \left( \bigcup^\infty_{t=1} \left\{ \left| \frac{1}{t} \sum^t_{s=1} X_s - \mathbb{E}[X_s] \right| \geq \sqrt{\frac{\log(4nt^2)}{2t}} \right\} \right) \leq \sum^\infty_{t=1} P \left( \left| \frac{1}{t} \sum^t_{s=1} X_s - \mathbb{E}[X_s] \right| \geq \sqrt{\frac{\log(4nt^2)}{2t}} \right). $$
>
>[Hoeffding's Inequality](https://en.wikipedia.org/wiki/Hoeffding%27s_inequality)μ™€ λ¬΄ν• κΈ‰μλ¥Ό μ‚¬μ©ν•μ—¬ λ‹¤μμ„ μ–»μ„ μ μμµλ‹λ‹¤.
>
>$$\begin{aligned}
>\sum^\infty_{t=1} P \left( \left| \frac{1}{t} \sum^t_{s=1} X_s - \mathbb{E}[X_s] \right| \geq  \sqrt{\frac{\log(4nt^2)}{2t}} \right) &\leq \sum^\infty_{t=1} 2e^{-\log(4nt^2)} \\
>&\leq \sum^\infty_{t=1} \frac{2}{4nt^2} \\ 
>&\leq \sum^\infty_{t=1} \frac{1}{2nt^2} \\
>&\leq \frac{1}{2n} \sum^\infty_{t=1} \frac{1}{t^2} \\
>&= \frac{1}{2n} \cdot \frac{\pi^2}{6} \\
>&\leq \frac{1}{2n} \cdot 2 = \frac{1}{n} &\blacksquare
>\end{aligned}$$

Non-stochasticν• ν™κ²½μ—μ„μ κ°€μ •μ€ $\lim_{\tau \to \infty} \ell_{i, \tau}$ κ°€ μ΅΄μ¬ν•λ©΄ λ‹¤μμ„ λ§μ΅±ν•λ” μ¦κ°€ν•μ§€ μ•λ” ν•¨μ $\gamma_i$ κ°€ μ΅΄μ¬ν•λ‹¤λ” κ²ƒμ…λ‹λ‹¤.

$$
\left| \ell_{i, t} - \lim_{\tau \to \infty} \ell_{i, \tau} \right| \leq \gamma_{i}(t) \to 0 \quad \text{ as} \quad t \to \infty
$$

μ„ λ‚΄μ©μ€ κ·Ήν•κ°’μΌλ΅μ μλ ΄μ€ λ³΄μ¥ν•΄μ£Όμ§€λ§ **μ–Όλ§λ‚ λΉ¨λ¦¬** $\gamma_i(t)$ κ°€ 0μΌλ΅ λ„λ‹¬ν•λ”μ§€λ” μ•λ ¤μ£Όμ§€ μ•μµλ‹λ‹¤. μ΄ μ‚¬μ‹¤μ€ λ‹¤μμ λ‘ κ°€μ§€ κ²°κ³Όλ΅ λ‚νƒ€λ‚Ό μ μμµλ‹λ‹¤.

1.   κ²°κµ­ Best Armμ΄ μ΅΄μ¬ν•κΈ°λ” ν•λ‹¤.
2.   Best ArmμΈμ§€ ν™•μΈν•  μ μ—†κ±°λ‚ Best Armμ μ •ν™•ν• κ°’μ„ μ•μ•„λ‚Ό μ μ—†λ‹¤.

λ³Έ λ…Όλ¬Έμ€ κΈ°μ΅΄μ— μ μ•λμ—λ Successive Halving Algorithmμ— λ€ν•΄ μ„ λ‚΄μ©μ„ ν†µν•΄ μ •ν•΄μ§„ μμ‚°(budget) λ‚΄μ—μ„ ν•μ΄νΌνλΌλ―Έν„°λ¥Ό μµμ ν™”ν•λ” ν¨κ³Όμ μ΄κ³  ν¨μ¨μ μΈ λ°©λ²•μ„ μ μ•ν•©λ‹λ‹¤.

## Successive Halving Algorithm

<center>
  <figure>
    <img src="/assets/images/2022-12-24-successive-halving-algorithm/sha_algorithm.png"
      alt="SHA Algorithm" style="zoom:33%;" loading="lazy"/>
    <figcaption style="text-align: center;">Pseudo-code for SHA</figcaption>
  </figure>
</center>

Successive Halving Algorithmμ€ λ‹¤μ μμ„λ΅ μ‘λ™ν•©λ‹λ‹¤.

-   μ…λ ¥κ°’μΌλ΅ μμ‚° $B$ μ™€ ν•μ΄νΌνλΌλ―Έν„° μ„¤μ •κ°’ κ°μ $n$ μ„ κ°–μµλ‹λ‹¤. 
    -   λ‘ κ°μ μ…λ ¥κ°’ μ¤‘ μμ‚° $B$ λ” $B \leftarrow n$, $B \leftarrow 2B$ λ΅ μ„¤μ •ν•λ” λ”λΈ”λ§ νΈλ¦­ (doubling trick)μΌλ΅ μ—†μ•¨ μ μμµλ‹λ‹¤. 
-   κ·Έ λ‹¤μ μµμ΄ ν•μ΄νΌνλΌλ―Έν„° μ„¤μ • μ§‘ν•© $S_0$ μ„ μ΄κΈ°ν™”ν•©λ‹λ‹¤.
-   λ‹¤μμ κ³Όμ •μ„ ν•λ‚μ ν•μ΄νΌνλΌλ―Έν„° μ„¤μ •μ΄ λ‚¨μ„ λ•κΉμ§€ λ°λ³µν•©λ‹λ‹¤.
    -   $S_k$ μ— λ‚¨μ•„ μλ” ν•μ΄νΌνλΌλ―Έν„° μ„¤μ •λ“¤λ΅ λ¨λΈμ„ $r_k$ Epoch λ§νΌ λ” ν•™μµν•κ³  $R_k$ λ¥Ό μ§€κΈκΉμ§€ ν•™μµν• Epoch μλ΅ μ„¤μ •ν•©λ‹λ‹¤.
    -   ν•™μµν• λ¨λΈ μ¤‘μ—μ„ μ†μ‹¤ ν•¨μ κ°’μΈ $\ell_{i, k}$ λ¥Ό κΈ°μ¤€μΌλ΅ μ„±λ¥μ΄ μΆ‹μ§€ μ•μ€ μ λ°μ ν•μ΄νΌνλΌλ―Έν„° μ„¤μ •κ°’μ„ λ²„λ¦½λ‹λ‹¤.
    -   λ‚¨μ€ ν•μ΄νΌνλΌλ―Έν„° μ„¤μ •μ„ $S_{k+1}$ λ΅ μ„¤μ •ν•©λ‹λ‹¤.
-   λ§μ§€λ§‰μΌλ΅ λ‚¨μ€ ν•μ΄νΌνλΌλ―Έν„° μ„¤μ •μ„ λ°ν™ν•©λ‹λ‹¤.

### μ‹¤μ  μμ‹

<center>
  <figure>
    <img src="/assets/images/2022-12-24-successive-halving-algorithm/sha_example.png"
      alt="Example for SHA" style="zoom:50%;" loading="lazy"/>
    <figcaption style="text-align: center;">Figure from [1]</figcaption>
  </figure>
</center>

μ΄ν•΄λ¥Ό μ„ν•΄μ„ μ§μ ‘ κ°’μ„ λ€μ…ν•μ—¬ μ•κ³ λ¦¬μ¦μ΄ μ–΄λ–»κ² μ‘λ™ν•λ”μ§€ μ•μ•„λ³΄λ„λ΅ ν•κ² μµλ‹λ‹¤. μ°μ„  μμ‚° $B$ λ¥Ό 32λ΅, ν•μ΄νΌνλΌλ―Έν„° μ„¤μ •κ°’ κ°μ $n$ μ€ 8λ΅ κ°€μ •ν•κ² μµλ‹λ‹¤. κ·Έλ¬λ©΄ μµμ΄ ν•μ΄νΌνλΌλ―Έν„° μ„¤μ • μ§‘ν•© $S_0$ μ ν¬κΈ°λ” λ‹Ήμ—°ν 8μ΄κ³ , μ•κ³ λ¦¬μ¦μ λ°λ³µμ€ $k=0$ λ¶€ν„° $k = \lfloor \log_2(n) \rfloor -1 = 2$ κΉμ§€ μ§„ν–‰ν•©λ‹λ‹¤.

1.   $k=0$
     -   $r_0 = \lfloor \frac{32}{ \|S_0\| \lceil \log_2(8) \rceil} \rfloor = \lfloor \frac{32}{8 \cdot 3} \rfloor = 1$
     -   $S_0$ λ‚΄ λ¨λ“  ν•μ΄νΌνλΌλ―Έν„°λ¥Ό 1 Epoch λ§νΌ ν•™μµν•κ³ , μ„±λ¥μ΄ λ‚®μ€ μ λ°μ„ λ²„λ¦½λ‹λ‹¤.
     -   λ”°λΌμ„ $\|S_1\| = 4$ κ°€ λ©λ‹λ‹¤.
2.   $k=1$
     -   $r_1 = \lfloor \frac{32}{\|S_1\| \lceil \log_2(8) \rceil} \rfloor = \lfloor \frac{32}{4 \cdot 3} \rfloor = 2$
     -   $S_1$ λ‚΄ λ¨λ“  ν•μ΄νΌνλΌλ―Έν„°λ¥Ό 2 Epochs λ§νΌ ν•™μµν•κ³ , μ„±λ¥μ΄ λ‚®μ€ μ λ°μ„ λ²„λ¦½λ‹λ‹¤.
     -   λ”°λΌμ„ $\|S_2\| = 2$ κ°€ λ©λ‹λ‹¤.
3.   $k=2$
     -   $r_2 = \lfloor \frac{32}{\|S_2\| \lceil \log_2(8) \rceil} \rfloor = \lfloor \frac{32}{2 \cdot 3} \rfloor = 5$
     -   $S_2$ λ‚΄ λ¨λ“  ν•μ΄νΌνλΌλ―Έν„°λ¥Ό 5 Epochs λ§νΌ ν•™μµν•κ³ , μ„±λ¥μ΄ λ‚®μ€ μ λ°μ„ λ²„λ¦½λ‹λ‹¤.
     -   λ”°λΌμ„ $\|S_3\| = 1$μ΄ λκ³ , $S_3$μ— μ΅΄μ¬ν•λ” λ‹¨ ν•λ‚μ ν•μ΄νΌνλΌλ―Έν„°λ¥Ό λ°ν™ν•©λ‹λ‹¤. μ΄ ν•μ΄νΌνλΌλ―Έν„°κ°€ SHAμ—μ„ μ°Ύλ” μµμ  ν•μ΄νΌνλΌλ―Έν„°μ…λ‹λ‹¤.

### SHAμ μλ ΄μ„± λ³΄μ¥

>   β οΈ μ•„λ λ‚΄μ©μ€ μμ„Έν• μ΄ν•΄λ¥Ό μ›ν•μ‹λ” κ²½μ°μ—λ§ λ³΄μ‹λ©΄ λ©λ‹λ‹¤. ν•„μμ μΈ λ‚΄μ©μ€ μ•„λ‹™λ‹λ‹¤. π€

λ³΄κΈ°μ—λ” κ°„λ‹¨ν•΄λ³΄μ΄λ”λ° μ΄ μ•κ³ λ¦¬μ¦μ΄ μµμ  ν•μ΄νΌνλΌλ―Έν„°λ¥Ό μ μ°Ύμ•„μ¤€λ‹¤λ” λ³΄μ¥, μ¦‰ **μ•κ³ λ¦¬μ¦μ μλ ΄μ„± λ³΄μ¥**μ€ μ–΄λ–»κ² λλ”κ±ΈκΉμ”? λ…Όλ¬Έμ—μ„λ” μ—¬λ¬ μ •λ¦¬(Theorem)λ¥Ό μ΄μ©ν•μ—¬ μλ ΄μ„±μ— λ€ν• λ‚΄μ©μ„ μ—„λ°€ν•κ² λ‹¤λ£¨κ³  μλ”λ°, λ³Έ ν¬μ¤νΈμ—μ„λ” μ•½μ‹μΌλ΅ λ‹¤λ£¨λ„λ΅ ν•κ² μµλ‹λ‹¤.

#### (1) μ „μ²΄ μƒν”μ μκ°€ μμ‚°μ„ λ„μ§€ μ•μ

μ°μ„  μ•κ³ λ¦¬μ¦μ—μ„ λ°μƒν•λ” μ „μ²΄ μƒν”μ΄ μμ‚° $B$λ¥Ό λ„μ§€ μ•λ” κ²ƒλ¶€ν„° λ³΄μ—¬μ•Ό ν•©λ‹λ‹¤. λ§μ•½ λ„κ² λλ‹¤λ©΄ μλ ΄μ€ λ‘μ§ΈμΉκ³  μ•κ³ λ¦¬μ¦μ μ ν¨μ„±μ΄ μ‚¬λΌμ§€λ‹κΉμ”. μ „μ²΄ μƒν”μ μλ” λ§¤ λ‹¨κ³„λ§λ‹¤μ ν•μ΄νΌνλΌλ―Έν„° μ§‘ν•© λ‚΄ μ›μ†μ μμ™€ ν•™μµν•  Epoch μλ¥Ό κ³±ν• κ²ƒκ³Ό κ°™μΌλ―€λ΅ λ‹¤μκ³Ό κ°™μµλ‹λ‹¤.

$$
\text{\#Samples} = \sum_{k=0}^{\lceil \log_2(n) \rceil -1} |S_k| \left\lfloor \frac{B}{|S_k| \lceil \log_2(n) \rceil} \right\rfloor
$$

μ—¬κΈ°μ„ floor functionμ μ„±μ§μ„ μ΄μ©ν•΄μ•Ό ν•©λ‹λ‹¤.. λ¶„λ¨μ— μλ” $\|S_k\|$ λ” μμ—°μμ΄κΈ° λ•λ¬Έμ— μ΄ κ°’μ„ floor function λ°–μΌλ΅ λΊμ„ λ• μ†μ«μ  μ•„λ μκ°€ λ°μƒν•΄μ„ $\|S_k\|$ λ¥Ό floor function λ°–μΌλ΅ λΊμ„ λ•κ°€ λ” ν° μκ°€ λ©λ‹λ‹¤. λ”°λΌμ„ λ‹¤μκ³Ό κ°™μ΄ μ •λ¦¬ν•  μ μμµλ‹λ‹¤.

$$
\begin{aligned}
\sum_{k=0}^{\lceil \log_2(n) \rceil -1} |S_k| \left\lfloor \frac{B}{|S_k| \lceil \log_2(n) \rceil} \right\rfloor &\leq \sum_{k=0}^{\lceil \log_2(n) \rceil -1} |S_k| \frac{1}{|S_k|} \left\lfloor \frac{B}{\lceil \log_2(n) \rceil} \right\rfloor \\
&= \sum_{k=0}^{\lceil \log_2(n) \rceil -1} \left\lfloor \frac{B}{\lceil \log_2(n) \rceil} \right\rfloor \\
& \leq \sum_{k=0}^{\lceil \log_2(n) \rceil -1} \frac{B}{\lceil \log_2(n) \rceil} = B
\end{aligned}
$$

λ”°λΌμ„ μ•κ³ λ¦¬μ¦μ—μ„ λ°μƒν•λ” μ „μ²΄ μƒν”μ μλ” μμ‚°λ³΄λ‹¤ μ‘κ±°λ‚ κ°™μµλ‹λ‹¤.

#### (2) μλ ΄μ„± λ³΄μ¥

λ¨λ“  ν•μ΄νΌνλΌλ―Έν„° μ„¤μ • $i = 1, 2, \cdots, n$μ— λ€ν•΄μ„ λ‹¤μμ„ μ •μν•©λ‹λ‹¤.

$$
\nu_i = \lim_{\tau \to \infty} \ell_{i, \tau}
$$

μ΄ κ°’μ€ μ„μ—μ„μ Non-stochasticν• ν™κ²½μ—μ„μ κ°€μ •μ— μν•΄ λ°λ“μ‹ μ΅΄μ¬ν•λ” κ°’μ…λ‹λ‹¤. μΌλ°μ„±μ„ μƒμ§€ μ•κ³  λ‹¤μκ³Ό κ°™μ΄ κ°€μ •ν•κ² μµλ‹λ‹¤. λ‹¨μν κ° ν•μ΄νΌνλΌλ―Έν„° μ„¤μ •μ„ μ„±λ¥ μμΌλ΅ μ¬μ •λ ¬ν–λ‹¤κ³  μƒκ°ν•λ©΄ λ©λ‹λ‹¤.

$$
\nu_1 \leq \nu_2 \leq \cdots \leq \nu_n.
$$

κ·Έλ¦¬κ³  κ°κ°μ $i = 1, 2, \cdots, n$μ— λ€ν•΄μ„ λ‹¤μμ„ λ§μ΅±ν•λ” point-wise smallest, non-increasingν• $t$μ— λ€ν• ν•¨μ $\gamma_i(t)$ λ¥Ό μ •μν•©λ‹λ‹¤.

$$
\left| \ell_{i, t} - \nu_i \right| \leq \gamma_i(t) \quad \forall t. \tag{*}
$$

$\gamma_i(t)$ λ” $\ell_{i, t}$ μ™€ κ·Έ κ·Ήν•κ°’ $\nu_i$ μ μ°¨μ΄λ¥Ό boundν•λ” μ–΄λ–¤ ν•¨μκ°€ λ©λ‹λ‹¤. μ—¬κΈ°κΉμ§€ μ •μκ°€ λμ—λ‹¤λ©΄ μ„μμ ν•μ΄νΌνλΌλ―Έν„° μ„¤μ • $i$ μ μ–΄λ–¤ μ‹μ  $t_i$ μ—μ„μ μ†μ‹¤ ν•¨μκ°’ $\ell\_{i, t_i}$ μ™€ κ°€μ¥ μ„±λ¥μ΄ μΆ‹κ² λ‚μ¬ ν•μ΄νΌνλΌλ―Έν„° μ„¤μ •μ μ–΄λ–¤ μ‹μ  $t_1$ μ—μ„μ μ†μ‹¤ ν•¨μκ°’ $\ell\_{1, t_1}$ μ μ°¨μ΄λ¥Ό κ³„μ‚°ν•΄λ΄…μ‹λ‹¤. 

$$
\begin{aligned}
\ell_{i, t_i} - \ell_{1, t_1} &= (\ell_{i, t_i} - \nu_i) + (\nu_1 - \ell_{1, t_1}) + 2\left(\frac{\nu_i - \nu_1}{2}\right) \\
& \geq -\gamma_i(t_i) - \gamma_1(t_1) + 2\left(\frac{\nu_i - \nu_1}{2}\right) & \text{by (*)}
\end{aligned}
$$

μ—¬κΈ°μ„ $\gamma_i(t)$ μ— λ€ν• μ μ‚¬ μ—­ν•¨μλ¥Ό κ³ λ ¤ν•©λ‹λ‹¤.

$$
\gamma_i^{-1}(\alpha) = \min \{ t \in \mathbb{N} \mid \gamma_i(t) \leq \alpha \} \quad \forall i \in [n]
$$

λ§μ•½ $t_i > \gamma_i^{-1} \left( \frac{\nu_i - \nu_1}{2} \right)$μ΄λ©΄μ„ $t_1 > \gamma_1^{-1} \left( \frac{\nu_i - \nu_1}{2} \right)$ λΌλ©΄ $\gamma_i(t)$ λ” non-increasing functionμ΄κΈ° λ•λ¬Έμ— λ‹¤μμ΄ μ„±λ¦½ν•©λ‹λ‹¤.

$$
\gamma_i(t_i) < \frac{\nu_i - \nu_1}{2} \quad \text{and} \quad \gamma_1(t_1) < \frac{\nu_i - \nu_1}{2}
$$

λ”°λΌμ„ μ‹ (12)λ” λ‹¤μκ³Ό κ°™μ΄ λ‹¤μ‹ μ“Έ μ μμµλ‹λ‹¤.

$$
\begin{aligned}
\ell_{i, t_i} - \ell_{1, t_1} &= (\ell_{i, t_i} - \nu_i) + (\nu_1 - \ell_{1, t_1}) + 2\left(\frac{\nu_i - \nu_1}{2}\right) \\
& \geq -\gamma_i(t_i) - \gamma_1(t_1) + 2\left(\frac{\nu_i - \nu_1}{2}\right) > 0
\end{aligned}
$$

λ³΄λ‹¤ μ—„λ°€ν•κ² λ§ν•μλ©΄ λ‹¤μμ΄ μ„±λ¦½ν•©λ‹λ‹¤.

$$
\min \{ t_i, t_1 \} > \max \left\{ \gamma_i^{-1} \left( \frac{\nu_i - \nu_1}{2} \right), \gamma_1^{-1} \left( \frac{\nu_i - \nu_1}{2} \right) \right\} \implies \ell_{i, t_i} > \ell_{1, t_i}
$$

μ΄λ¥Ό ν†µν•΄ μ λ‹Ήν• μ„μμ λ‘ μ‹μ , $t_i$μ™€ $t_1$μ—μ„ $\ell_{i, t_i} > \ell_{1, t_1}$ κ°€ μ„±λ¦½ν•λ‹¤λ©΄ ν•™μµ μ¤‘κ°„μ μ†μ‹¤ ν•¨μλ¥Ό λΉ„κµν•λ” κ²ƒλ§μΌλ΅ μµμΆ… μλ ΄κ°’μΈ $\nu_i$μ™€ $\nu_1$μ λ€μ† κ΄€κ³„λ¥Ό λΉ„κµν•  μ μλ‹¤λ” κ²ƒμ„ μ• μ μμµλ‹λ‹¤. μ§κ΄€μ μΌλ΅ μƒκ°ν•΄λ³Έλ‹¤λ©΄ $\gamma_i(t)$κ°€ λ‘ μλ ΄κ°’ $\nu_i$μ™€ $\nu_1$μ ν‰κ· λ³΄λ‹¤ μ‘μ•„μ§€κ² λλ” $t$λ” **μ¶©λ¶„ν ν° μ**κ°€ λ  κ²ƒμ…λ‹λ‹¤. $t$λ¥Ό ν¬κ² μ΅κΈ° μ„ν•΄μ„  μ΄ μμ‚° $B$λ¥Ό μ¶©λ¶„ν ν¬κ² μ΅μ•„μ•Ό ν•©λ‹λ‹¤. λ”°λΌμ„ μ¶©λ¶„ν ν° $B$ κ°’μ„ κ°–λ”λ‹¤λ©΄ μ΄λ” κ²°κµ­ SHAκ°€ μµμ μ ν•μ΄νΌνλΌλ―Έν„° μ„¤μ •μ„ μ°Ύμ•„λ‚΄κΈ°μ— μ¶©λ¶„ν•κ² λ©λ‹λ‹¤.

## λ νΌλ°μ¤

[1] Feurer, Matthias, and Frank Hutter. "Hyperparameter optimization." *Automated machine learning*. Springer, Cham, 2019. 3-33.