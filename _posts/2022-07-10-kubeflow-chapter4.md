---
title: Kubeflow for ML - Chaper 4
tags: [kubeflow, mlops]
category: Kubeflow
aside:
  toc: true
show_category: true
---

Chapter 4: Kubeflow Pipelines

<!--more-->


>   ğŸ‘€ ë³¸ í¬ìŠ¤íŠ¸ëŠ” [Kubeflow for Machine Learning](https://oreilly.com/library/view/kubeflow-for-machine/9781492050117/) ì±…ì„ ë°œì·Œ/ìš”ì•½í•˜ë©´ì„œ í•„ìš”í•œ ë‚´ìš©ì€ ì¶”ê°€í•˜ì—¬ ì‘ì„±í•˜ì˜€ìŠµë‹ˆë‹¤.
>
>   -   [Chapter 1: Kubeflow: What It is and Who It Is For](/kubeflow/2022/05/08/kubeflow-chapter1.html)
>   -   [Chapter 2: Hello Kubeflow](/kubeflow/2022/05/15/kubeflow-chapter2.html)
>   -   [Chapter 3: Kubeflow Design: Beyond the Basics](/kubeflow/2022/06/19/kubeflow-chapter3.html)
>   -   [Chapter 4: Kubeflow Pipelines](/kubeflow/2022/07/10/kubeflow-chapter4.html)
>   -   Chapter 5: Data and Feature Preparation
>   -   Chapter 6: Artifact and Metadata Store
>   -   Chapter 7: Training a Machine Learning Model
>   -   Chapter 8: Model Inference
>   -   Chapter 9: Case Study Using Multiple Tools
>   -   Chapter 10: Hyperparameter Tuning And Automated Machine Learning

## Getting Started with Pipelines

Kubeflow Pipelines í”Œë«í¼ì€ ë‹¤ìŒì„ í¬í•¨í•˜ê³  ìˆìŠ¤ë¹ˆë‹¤.

-   íŒŒì´í”„ë¼ì¸ì„ ê´€ë¦¬, ì¶”ì í•˜ê³  ì‹¤í–‰í•  ìˆ˜ ìˆë„ë¡ í•˜ëŠ” UI
-   íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ ìŠ¤ì¼€ì¤„ë§ì„ ìœ„í•œ ì—”ì§„
-   Pythonì—ì„œ íŒŒì´í”„ë¼ì¸ì„ ì •ì˜, êµ¬ì¶•, ë°°í¬í•˜ê¸° ìœ„í•œ SDK
-   SDKì™€ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ì„ ìœ„í•œ ë…¸íŠ¸ë¶ ì§€ì›

### Building a Sipmle Pipeline in Python

Kubeflow Pipelinesì€ Argoë¡œ ì‹¤í–‰ë˜ëŠ” YAML íŒŒì¼ë¡œ ì €ì¥ë©ë‹ˆë‹¤. Kubeflowì—ì„œëŠ” Python DSL (Domain-Specific Language)ì„ ì´ìš©í•´ íŒŒì´í”„ë¼ì¸ì„ ì‘ì„±í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. íŒŒì´í”„ë¼ì¸ì€ ë³¸ì§ˆì ìœ¼ë¡œ ì»¨í…Œì´ë„ˆ ì‹¤í–‰ìœ¼ë¡œ êµ¬ì„±ëœ ê·¸ë˜í”„ì…ë‹ˆë‹¤.  ì‹¤í–‰í•  ì»¨í…Œì´ë„ˆë¥¼ ìˆœì„œëŒ€ë¡œ ì§€ì •í•  ë¿ë§Œ ì•„ë‹ˆë¼ ì „ì²´ íŒŒì´í”„ë¼ì¸ê³¼ ì»¨í…Œì´ë„ˆë“¤ ì‚¬ì´ì— ì¸ìë¥¼ ì „ë‹¬í•  ìˆ˜ë„ ìˆìŠµë‹ˆë‹¤.

íŒŒì´í”„ë¼ì¸ì€ ë‹¤ìŒì˜ ìˆœì„œë¡œ ì‘ì—…í•©ë‹ˆë‹¤.

-   ì»¨í…Œì´ë„ˆ ìƒì„± (ê°„ë‹¨í•œ Python í•¨ìˆ˜ë‚˜ ë„ì»¤ ì»¨í…Œì´ë„ˆ)
-   í•´ë‹¹ ì»¨í…Œì´ë„ˆ ë¿ë§Œ ì•„ë‹ˆë¼ ëª…ë ¹ì¤„ ì¸ìˆ˜, ë°ì´í„° íƒ‘ì¬, ì»¨í…Œì´ë„ˆì— ì „ë‹¬í•  ë³€ìˆ˜ ë“±ì„ ì°¸ì¡°í•˜ëŠ” ì‘ì—…(operation) ìƒì„±
-   ë³‘ë ¬ë¡œ ì§„í–‰í•  ì‘ì—…ê³¼ ì‚¬ì „ ì‘ì—… ë“±ì„ ì •ì˜í•˜ì—¬ ìˆœì„œëŒ€ë¡œ ì§€ì •
-   Pythonìœ¼ë¡œ ì •ì˜í•œ íŒŒì´í”„ë¼ì¸ì„ Kubeflow Pipelinesì´ ì‚¬ìš©í•  ìˆ˜ ìˆë„ë¡ YAMLë¡œ ì»´íŒŒì¼

ë‹¤ìŒì€ ê°„ë‹¨í•œ íŒŒì´í”„ë¼ì¸ì„ ë§Œë“œëŠ” ì˜ˆì œì…ë‹ˆë‹¤. ìš°ì„  íŒŒì´í”„ë¼ì¸ì„ êµ¬ì„±í•˜ëŠ” ì˜¤í¼ë ˆì´ì…˜ì„ ìƒì„±í•˜ëŠ” ì½”ë“œì…ë‹ˆë‹¤.

```python
from collections import namedtuple
from typing import NamedTuple

import kfp
from kfp import compiler
import kfp.dsl as dsl
import kfp.notebook
import kfp.components as comp

def add(a: float, b: float) -> float:
    """Calculates sum of two arguments"""
    return a+b

# í•¨ìˆ˜ë¥¼ íŒŒì´í”„ë¼ì¸ ì˜¤í¼ë ˆì´ì…˜ìœ¼ë¡œ ë³€í™˜
add_op = comp.func_to_container_op(add)

def my_divmod(dividend: float, divisor: float) -> \
	NamedTuple("MyDivmodOutput", [("quotient", float), ("remainder", float)]):
    """Divides two numbers and calculate the quotient and remainder"""
    # ì»´í¬ë„ŒíŠ¸ í•¨ìˆ˜ ì•ˆì— ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸
    import numpy as np
    
    def divmod_helper(dividend, divisor):
        return np.divmod(dividend, divisor)
    
    (quotient, remainder) = divmod_helper(dividend, divisor)
    
    divmod_output = namedtuple("MyDivmodOutput", ["quotient", "remainder"])
    return divmod_output(quotient, remainder)

# ìœ„ í•¨ìˆ˜ë¥¼ íŒŒì´í”„ë¼ì¸ ì˜¤í¼ë ˆì´ì…˜ìœ¼ë¡œ ë³€í™˜í•˜ë©´ì„œ ë² ì´ìŠ¤ ì´ë¯¸ì§€ ëª…ì‹œ
divmod_op = comp.func_to_container_op(
    my_divmod, 
    base_image="tensorflow/tensorflow:1.14.0-py3"
)
```

í•„ìš”í•œ ì˜¤í¼ë ˆì´ì…˜ì„ ë‹¤ ë§Œë“¤ì—ˆë‹¤ë©´ ì´ì œ íŒŒì´í”„ë¼ì¸ì„ êµ¬ì„±í•˜ë©´ ë©ë‹ˆë‹¤.

```python
@dsl.pipeline(
	name="Calculation pipeline",
    description="A toy pipeline that performs arithmetic calculations."
)
def calc_pipeline(
	a="a",
    b="7",
    c="17",
):
    # íŒŒì´í”„ë¼ì¸ íŒŒë¼ë¯¸í„°ë¥¼ ì „ë‹¬í•˜ê³  ì˜¤í¼ë ˆì´ì…˜ ì¸ìë¡œ ìƒìˆ˜ë¥¼ ì „ë‹¬
    add_task = add_op(a, 4)
    
    # ìœ„ì—ì„œ ìƒì„±í•œ íƒœìŠ¤í¬ì˜ ì•„ì›ƒí’‹ì„ ë‹¤ìŒ ì˜¤í¼ë ˆì´ì…˜ì˜ ì¸ìë¡œ ì‚¬ìš©
    # ìœ„ ì˜¤í¼ë ˆì´ì…˜ì€ ë‹¨ì¼ê°’ì„ ë°˜í™˜í•˜ë¯€ë¡œ ë‹¨ìˆœíˆ `task.output`ìœ¼ë¡œ ì „ë‹¬
    divmod_task = divmod_op(add_task.output, b)
    
    # ìœ„ ì˜¤í¼ë ˆì´ì…˜ì€ ì—¬ëŸ¬ ê°’ì„ ë°˜í™˜í•˜ë¯€ë¡œ `task.outputs["output_name"]`ìœ¼ë¡œ
    # ê°’ ì „ë‹¬
    result_task = add_op(divmod_task.outputs["quotient"], c)
```

ë§ˆì§€ë§‰ìœ¼ë¡œ ì‹¤í–‰ê³¼ ì‹¤í—˜ì— ëŒ€í•œ ë§í¬ë¥¼ ë°˜í™˜í•˜ë„ë¡ ì‹¤í–‰ìš© íŒŒì´í”„ë¼ì¸ì„ í´ë¼ì´ì–¸íŠ¸ì— ë³´ëƒ…ë‹ˆë‹¤.

```python
client = kfp.Client()
arguments = {"a": "7", "b": "8"}
client.create_run_from_pipeline_func(
    calc_pipeline, 
    arguments=arguments
)
```

ì˜¬ë°”ë¥´ê²Œ ì‹¤í–‰ì´ ë˜ë©´ ë§í¬ê°€ ëœ¨ëŠ”ë° ì´ë¥¼ í´ë¦­í•˜ë©´ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ ê²°ê³¼ë¥¼ ë³¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.

<center>
  <figure>
    <img src="/assets/images/2022-07-10-kubeflow-chapter4/pipeline-execution.png"
      alt="Pipeline execution" style="zoom:50%;" loading="lazy"/>
    <figcaption style="text-align: center;">Pipeline execution</figcaption>
  </figure>
</center>

### Storing Data Between Steps

Kubeflowì—ì„œëŠ” ì»¨í…Œì´ë„ˆë¡œ ë°ì´í„°ë¥¼ ì „ë‹¬í•  ë•Œ ë‘ ê°€ì§€ ë°©ì‹ì„ ì§€ì›í•©ë‹ˆë‹¤. Kubernetes í´ëŸ¬ìŠ¤í„° ë‚´ì˜ í¼ì‹œìŠ¤í„´íŠ¸ ë³¼ë¥¨ (persistent volumes)ê³¼ S3ì™€ ê°™ì€ í´ë¼ìš°ë“œ ì €ì¥ì†Œ ì˜µì…˜ì…ë‹ˆë‹¤.

í¼ì‹œìŠ¤í„´íŠ¸ ë³¼ë¥¨ì€ ì €ì¥ì†Œ ë ˆì´ì–´ë¥¼ ì¶”ìƒí™”í•©ë‹ˆë‹¤. í¼ì‹œìŠ¤í„´íŠ¸ ë³¼ë¥¨ì€ ë²¤ë”ì— ë”°ë¼ í”„ë¡œë¹„ì €ë‹ ì†ë„ê°€ ëŠë¦¬ê³  IO ì œí•œì´ ìˆì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì €ì¥ì†Œ í´ë˜ìŠ¤ëŠ” ë‹¤ìŒ ì¤‘ í•˜ë‚˜ê°€ ë©ë‹ˆë‹¤.

-   ReadWriteOnce : í•˜ë‚˜ì˜ ë…¸ë“œì—ì„œ í•´ë‹¹ ë³¼ë¥¨ì´ ì½ê¸°-ì“°ê¸°ë¡œ ë§ˆìš´íŠ¸ë  ìˆ˜ ìˆìŒ
-   ReadOnlyMany : ë³¼ë¥¨ì´ ë‹¤ìˆ˜ì˜ ë…¸ë“œì—ì„œ ì½ê¸° ì „ìš©ìœ¼ë¡œ ë§ˆìš´íŠ¸ë  ìˆ˜ ìˆìŒ
-   ReadWriteMany : ë³¼ë¥¨ì´ ë‹¤ìˆ˜ì˜ ë…¸ë“œì—ì„œ ì½ê¸°-ì“°ê¸°ë¡œ ë§ˆìš´íŠ¸ë  ìˆ˜ ìˆìŒ

Kubeflow Pipelinesì—ì„œ `VolumeOp`ë¥¼ ì‚¬ìš©í•˜ë©´ ìë™ìœ¼ë¡œ ê´€ë¦¬ë˜ëŠ” í¼ì‹œìŠ¤í„´íŠ¸ ë³¼ë¥¨ì„ ìƒì„±í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. 

```python
dvop = dsl.VolumeOp(name="create_pvc",
                    resource_name="my-pvc-2",
                    size="5Gi",
                    modes=dsl.VOLUME_MODE_RWO)
```

ì˜¤í¼ë ˆì´ì…˜ì— ë³¼ë¥¨ì„ ì¶”ê°€í•˜ê³  ì‹¶ë‹¤ë©´ `add_pvolumes`ì„ í˜¸ì¶œí•˜ì—¬ ì‚¬ìš©í•˜ë©´ ë©ë‹ˆë‹¤. 

```python
download_data_op(year).add_pvolumes({"/data_processing": dvop.volumeÂ´})
```

Kubeflowì˜ ë¹ŒíŠ¸ì¸ `file_output` ë©”ì»¤ë‹ˆì¦˜ì€ íŒŒì´í”„ë¼ì¸ ì‚¬ì´ì—ì„œ íŠ¹ì • ë¡œì»¬ íŒŒì¼ì„ MinIOë¡œ ìë™ìœ¼ë¡œ ì „ì†¡í•  ìˆ˜ ìˆê²Œ í•©ë‹ˆë‹¤. `file_output`ì„ ì‚¬ìš©í•˜ì—¬ ì»¨í…Œì´ë„ˆ ë‚´ì— íŒŒì¼ì„ ì“¸ ìˆ˜ë„ ìˆê³  `ContainerOp`ì— íŒŒë¼ë¯¸í„°ë¥¼ íŠ¹ì •í•  ìˆ˜ë„ ìˆìŠµë‹ˆë‹¤.

```python
fecth = kfp.dsl.ContainerOp(
	name="download",
    image="busybox",
    command=["sh", "-c"],
    arguments=[
        "sleep 1;",
        "mkdir -p /tmp/data;",
        "wget " + data_url + 
        " -O /tmp/dat/result.csv"
    ],
    file_outputs={"downloaded", "/tmp/data"}
)
```

## Introduction to Kubeflow Pipelines Components

### Argo: the Foundation of Pipelines

Kubeflow PipelinesëŠ” Kubenetesë¥¼ ì‚¬ìš©í•˜ëŠ” ì»¨í…Œì´ë„ˆ ë„¤ì´í‹°ë¸Œ ì›Œí¬í”Œë¡œìš° ì—”ì§„ì¸ Argo Workflowsë¥¼ ë¹Œë“œí•©ë‹ˆë‹¤. Kubeflowë¥¼ ì„¤ì¹˜í•  ë•Œë„ ëª¨ë“  Argo ì»´í¬ë„ŒíŠ¸ê°€ ì„¤ì¹˜ë˜ëŠ”ë°ìš”. Kubeflow Pipelinesì„ ì‚¬ìš©í•˜ê¸° ìœ„í•´ Argoë¥¼ ì„¤ì¹˜í•  í•„ìš”ëŠ” ì—†ì§€ë§Œ Argo ì»¤ë§¨ë“œë¼ì¸ì„ í†µí•´ íŒŒì´í”„ë¼ì¸ì„ ë””ë²„ê¹…í•  ë•Œ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. Argo ì„¤ì¹˜ëŠ” ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤.

```bash
$ # Download the binary 
$ curl -sLO https://github.com/argoproj/argo/releases/download/v2.8.1/argo-linux-amd64

$ # Make binary executable 
$ chmod +x argo-linux-amd64

$ # Move binary to path 
$ mv ./argo-linux-amd64 ~/bin/argo
```

ì„¤ì¹˜ê°€ ì™„ë£Œëë‹¤ë©´ Manifestë¥¼ ì´ìš©í•´ Argo Podì„ ë„ì›Œì¤ë‹ˆë‹¤.

```bash
$ kubectl create ns argo
$ kubectl apply -n argo -f https://raw.githubusercontent.com/argoproj/argo-workflows/master/manifests/quick-start-postgres.yaml
```

 ì´ì œ ë‹¤ìŒì˜ ëª…ë ¹ì–´ë¡œ Kubeflow ë„¤ì„ìŠ¤í˜ì´ìŠ¤ë¡œ íŒŒì´í”„ë¼ì¸ì„ ë³´ë‚¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.

```bash
$ argo submit -n kubeflow --watch https://raw.githubusercontent.com/argoproj/argo-workflows/master/examples/hello-world.yaml

$ argo list -n kubeflowgg
NAME                STATUS      AGE   DURATION   PRIORITY
hello-world-hxkrs   Succeeded   4h    26s        0

$ argo get hello-world-hxkrs -n kubeflow
Name:                hello-world-hxkrs
Namespace:           kubeflow
ServiceAccount:      default
Status:              Succeeded
Conditions:
 PodRunning          False
 Completed           True
Created:             Sun Jul 03 16:57:04 +0900 (4 hours ago)
Started:             Sun Jul 03 16:57:04 +0900 (4 hours ago)
Finished:            Sun Jul 03 16:57:30 +0900 (4 hours ago)
Duration:            26 seconds
ResourcesDuration:   14s*cpu,4s*memory

STEP                  TEMPLATE  PODNAME            DURATION  MESSAGE
 âœ” hello-world-hxkrs  whalesay  hello-world-hxkrs  15s
 
$ argo logs hello-world-hxkrs -n kubeflow
hello-world-hxkrs: time="2022-07-03T07:57:12.005Z" level=info msg="capturing logs" argo=true
hello-world-hxkrs:  _____________
hello-world-hxkrs: < hello world >
hello-world-hxkrs:  -------------
hello-world-hxkrs:     \
hello-world-hxkrs:      \
hello-world-hxkrs:       \
hello-world-hxkrs:                     ##        .
hello-world-hxkrs:               ## ## ##       ==
hello-world-hxkrs:            ## ## ## ##      ===
hello-world-hxkrs:        /""""""""""""""""___/ ===
hello-world-hxkrs:   ~~~ {~~ ~~~~ ~~~ ~~~~ ~~ ~ /  ===- ~~~
hello-world-hxkrs:        \______ o          __/
hello-world-hxkrs:         \    \        __/
hello-world-hxkrs:           \____\______/

$ argo delete hello-world-hxkrs -n kubeflow
Workflow 'hello-world-hxkrs' deleted
```

### What Kubeflow Pipelines Adds to Argo Workflow

Argoë¥¼ ì§ì ‘ ì‚¬ìš©í•˜ë ¤ë©´ YAMLë¡œ ì›Œí¬í”Œë¡œìš°ë¥¼ ì •ì˜í•´ì•¼ í•˜ê³  ì½”ë“œë¥¼ ì»¨í…Œì´ë„ˆí™”í•´ì•¼ í•˜ëŠ”ë° ë§¤ìš° ê¹Œë‹¤ë¡œìš´ ì‘ì—…ì…ë‹ˆë‹¤. ë°˜ë©´ Kubeflow Pipelinesì„ ì‚¬ìš©í•˜ë©´ Python APIë¥¼ ì´ìš©í•´ íŒŒì´í”„ë¼ì¸ì„ ì •ì˜í•˜ê³  ìƒì„±í•  ìˆ˜ ìˆê¸° ë•Œë¬¸ì— í¸í•˜ê²Œ ì‘ì—…í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ë” ë‚˜ì•„ê°€ ML ê´€ë ¨ ì»´í¬ë„ŒíŠ¸ë¥¼ ì¶”ê°€í•˜ê¸°ì—ë„ í›¨ì”¬ ìš©ì´í•©ë‹ˆë‹¤.

### Building a Pipeline Using Existing Images

Kubeflow Pipelinesì€ ì´ë¯¸ ë¹Œë“œëœ Docker ì´ë¯¸ì§€ë¥¼ ì´ìš©í•´ ì—¬ëŸ¬ ì–¸ì–´ë¡œ êµ¬í˜„ëœ ê²ƒë“¤ì„ ì‹¤í–‰í•´ ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´ì…˜í•˜ëŠ” ê¸°ëŠ¥ì„ ê°–ê³  ìˆìŠµë‹ˆë‹¤.

ë˜í•œ Python ë‚´ì—ì„œ ì§ì ‘ Kubernetes í•¨ìˆ˜ë¥¼ ì‚¬ìš©í•˜ë„ë¡ Kubernetes í´ë¼ì´ì–¸íŠ¸ë¥¼ ì„í¬íŠ¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

```python
from kubernetes import client as k8s_client
```

ê·¸ë¦¬ê³  íŒŒì´í”„ë¼ì¸ì—ì„œ ì‹¤í—˜ì€ í•œ ë²ˆë§Œ ë§Œë“¤ ìˆ˜ ìˆê¸° ë•Œë¬¸ì— ê¸°ì¡´ì˜ ì‹¤í—˜ ì´ë¦„ì„ í†µí•´ í•´ë‹¹ ì‹¤í—˜ì„ ì‚¬ìš©í•  ìˆ˜ë„ ìˆìŠµë‹ˆë‹¤.

```python
client = kfp.Client()
exp = client.get_experiment(experiment_name="mdupdate")
```

ë‹¤ìŒ ì˜ˆì œëŠ” ì´ë¯¸ ë¹Œë“œë˜ì–´ ìˆëŠ” ì´ë¯¸ì§€ë“¤ì„ ì´ìš©í•˜ì—¬ íŒŒì´í”„ë¼ì¸ì„ ìƒì„±í•˜ëŠ” ì½”ë“œì…ë‹ˆë‹¤. ì•„ë˜ ì½”ë“œì—ì„œ í”„ë¦¬ë¹Œë“œëœ ì»¨í…Œì´ë„ˆëŠ” `MINIO_*` í™˜ê²½ ë³€ìˆ˜ë¡œ ì„¤ì •ë˜ì–´ ìˆì–´ `add_env_variable`ì„ í˜¸ì¶œí•˜ì—¬ ë¡œì»¬ MinIOë¥¼ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ê·¸ë¦¬ê³  ê° ë‹¨ê³„ë¥¼ ëª…ì‹œí•˜ê¸° ìœ„í•´ `after` ë©”ì„œë“œë¥¼ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

```python
@dsl.pipeline(
    name='Recommender model update',
    description='Demonstrate usage of pipelines for multi-step model update')
def recommender_pipeline():
    # Load new data
    data = dsl.ContainerOp(
        name='updatedata',
        image='lightbend/recommender-data-update-publisher:0.2') \
      .add_env_variable(k8s_client.V1EnvVar(name='MINIO_URL', value='http://minio-service.kubeflow.svc.cluster.local:9000')) \
      .add_env_variable(k8s_client.V1EnvVar(name='MINIO_KEY', value='minio')) \
      .add_env_variable(k8s_client.V1EnvVar(name='MINIO_SECRET', value='minio123'))
    # Train the model
    train = dsl.ContainerOp(
        name='trainmodel',
        image='lightbend/ml-tf-recommender:0.1') \
      .add_env_variable(k8s_client.V1EnvVar(name='MINIO_URL', value='minio-service.kubeflow.svc.cluster.local:9000')) \
      .add_env_variable(k8s_client.V1EnvVar(name='MINIO_KEY', value='minio')) \
      .add_env_variable(k8s_client.V1EnvVar(name='MINIO_SECRET', value='minio123'))
    train.after(data)
    # Publish new model model
    publish = dsl.ContainerOp(
        name='publishmodel',
        image='lightbend/recommender-model-publisher:0.2') \
      .add_env_variable(k8s_client.V1EnvVar(name='MINIO_URL', value='http://minio-service.kubeflow.svc.cluster.local:9000')) \
      .add_env_variable(k8s_client.V1EnvVar(name='MINIO_KEY', value='minio')) \
      .add_env_variable(k8s_client.V1EnvVar(name='MINIO_SECRET', value='minio123')) \
      .add_env_variable(k8s_client.V1EnvVar(name='KAFKA_BROKERS', value='cloudflow-kafka-brokers.cloudflow.svc.cluster.local:9092')) \
      .add_env_variable(k8s_client.V1EnvVar(name='DEFAULT_RECOMMENDER_URL', value='http://recommendermodelserver.kubeflow.svc.cluster.local:8501')) \
      .add_env_variable(k8s_client.V1EnvVar(name='ALTERNATIVE_RECOMMENDER_URL', value='http://recommendermodelserver1.kubeflow.svc.cluster.local:8501'))
    publish.after(train)
```

ì´ íŒŒì´í”„ë¼ì¸ì„ ì»´íŒŒì¼í•˜ê±°ë‚˜ ë°”ë¡œ `create_run_from_pipeline_func`ìœ¼ë¡œ ì‹¤í–‰í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

```python
from kfp import compiler
compiler.Compiler().compile(recommender_pipeline, "pipeline.tar.gz")

run = client.run_pipeline(exp.id, "pipeline1", "pipeline.tar.gz")
```

### Kubeflow Pipeline Components

Kubeflow Pipelinesì€ ë‹¤ë¥¸ Kubernetes ë¦¬ì†ŒìŠ¤ë‚˜ `dataproc`ê³¼ ê°™ì€ ì™¸ë¶€ ì˜¤í¼ë ˆì´ì…˜ì„ ì‚¬ìš©í•˜ëŠ” ì»´í¬ë„ŒíŠ¸ë„ ì œê³µí•©ë‹ˆë‹¤. Kubeflow ì»´í¬ë„ŒíŠ¸ëŠ” ML íˆ´ì„ íŒ¨í‚¤ì§•í•˜ëŠ” ë™ì‹œì— ì‚¬ìš©í•œ ì»¨í…Œì´ë„ˆë‚˜ CRDë¥¼ ì¶”ìƒí™”í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

`func_to_container` ê°™ì€ ì»´í¬ë„ŒíŠ¸ëŠ” Python ì½”ë“œë¡œ ì‚¬ìš©í•  ìˆ˜ ìˆê³ , ì–´ë–¤ ì»´í¬ë„ŒíŠ¸ëŠ” Kubeflowì˜ `component.yaml` ì‹œìŠ¤í…œì„ ì‚¬ìš©í•˜ì—¬ ë¶ˆëŸ¬ì™€ì•¼ í•©ë‹ˆë‹¤. ë³¸ ì±…ì—ì„œ ì œì•ˆí•˜ëŠ” Kubeflow ì»´í¬ë„ŒíŠ¸ë¥¼ ì œëŒ€ë¡œ ì‚¬ìš©í•˜ëŠ” ë°©ë²•ì€ ì €ì¥ì†Œì˜ íŠ¹ì • íƒœê·¸ë¥¼ `load_components_from_file`ì„ ì´ìš©í•´ ë‹¤ìš´ë¡œë“œí•˜ëŠ” ê²ƒì…ë‹ˆë‹¤.

```bash
$ wget https://github.com/kubeflow/pipelines/archive/0.2.5.tar.gz
$ tar -xvf 0.2.5.tar.gz
```

ì´ì œ ë‹¤ìš´ë¡œë“œí•œ ì»´í¬ë„ŒíŠ¸ë¥¼ ë¶ˆëŸ¬ì˜¬ ìˆ˜ ìˆìŠµë‹ˆë‹¤.

```python
gcs_download_component = kfp.components.load_component_from_file(
	"pipelines-0.2.5/components/google-cloud/storage/download/component.yaml"
)
```

GCS ë‹¤ìš´ë¡œë“œ ì»´í¬ë„ŒíŠ¸ëŠ” Google Cloud Storage ê²½ë¡œë¥¼ ì…ë ¥í•˜ì—¬ íŒŒì¼ì„ ë‹¤ìš´ë¡œë“œ í•  ìˆ˜ ìˆê²Œ í•©ë‹ˆë‹¤.

```python
dl_op = gcs_download_component(
	gcs_path="gs://ml-pipeline-playground/tensorflow-tfx-repo/tfx/components/testdata/external/csv"
)
```

## Advanced Topic in Pipelines

### Conditional Execution of Pipeline Stages

Kubeflow Pipelinesì—ì„œëŠ” `dsl.Condition`ì„ ì´ìš©í•´ì„œ ì¡°ê±´ì— ë§ê²Œ íŒŒì´í”„ë¼ì¸ì„ ì‹¤í–‰í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. í•¨ìˆ˜ ëª‡ ê°œë¥¼ ì˜¤í¼ë ˆì´ì…˜ìœ¼ë¡œ ë°”ê¾¸ê² ìŠµë‹ˆë‹¤.

```python
import kfp
from kfp import dsl
from kfp.components import func_to_container_op, InputPath, OutputPath

@func_to_container_op
def get_random_int_op(minimum: int, maximum: int) -> int:
    """Generate a random number between minimum and maximum (inclusive)"""
    import random
    result = random.randint(minimum, maximum)
    print(result)
    return result

@func_to_container_op
def process_small_op(data: int):
    """Process small numbers."""
    print("Processing small result", data)
    return

@func_to_container_op
def process_medium_op(data: int):
    """Process medium numbers."""
    print("Processing medium result", data)
    return

@func_to_container_op
def process_large_op(data: int):
    """Process large numbers."""
    print("Processing large result", data)
    return
```

ì—¬ê¸°ì— `dsl.Condition`ì„ ì´ìš©í•´ ì¡°ê±´ì— ë§ëŠ” ì˜¤í¼ë ˆì´ì…˜ì„ ì‹¤í–‰í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

```python
@dsl.pipeline(
	name="Conditional execution pipeline",
    description="Shows how to use dsl.Condition()."
)
def conditional_pipeline():
    number = get_random_int_op(0, 100).output
    with dsl.Condition(number < 10):
        process_small_op(number)
    with dsl.Condition(number > 10 and number < 50):
        process_medium_op(number)
    with dsl.Condition(number > 50):
        process_large_op(number)

kfp.Client().create_run_from_pipeline_func(conditional_pipeline, arguments={})
```

ì‹¤í–‰ì´ ì™„ë£Œë˜ë©´ ë‹¤ìŒê³¼ ê°™ì€ ì‹¤í–‰ ê·¸ë˜í”„ë¥¼ ì–»ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.

<center>
  <figure>
    <img src="/assets/images/2022-07-10-kubeflow-chapter4/conditional-execution.png"
      alt="Conditional execution" style="zoom:50%;" loading="lazy"/>
    <figcaption style="text-align: center;">Conditional execution</figcaption>
  </figure>
</center>

### Running Pipelines on Schedule

íŒŒì´í”„ë¼ì¸ì„ ìŠ¤ì¼€ì¤„ë§í•  ìˆ˜ë„ ìˆìŠµë‹ˆë‹¤. íŒŒì´í”„ë¼ì¸ì„ í•œ ë²ˆ ì—…ë¡œë“œ í•œ ë‹¤ìŒ ì‹¤í–‰ íƒ€ì…ì„ "Recurring"ìœ¼ë¡œ ì„¤ì •í•œ ë‹¤ìŒ ìŠ¤ì¼€ì¤„ë§í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

<center>
  <figure>
    <img src="/assets/images/2022-07-10-kubeflow-chapter4/pipeline-scheduling.png"
      alt="Pipeline scheduling" style="zoom:50%;" loading="lazy"/>
    <figcaption style="text-align: center;">Pipeline scheduling</figcaption>
  </figure>
</center>
